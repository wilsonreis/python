### ğŸ“Œ **DistÃ¢ncia de Manhattan: Entendimento MatemÃ¡tico e AplicaÃ§Ã£o no KNN em Python**  

A **distÃ¢ncia de Manhattan** Ã© uma das formas de medir a distÃ¢ncia entre dois pontos em um espaÃ§o multidimensional. Ela Ã© conhecida tambÃ©m como **distÃ¢ncia do tÃ¡xi** ou **distÃ¢ncia L1**, porque reflete o caminho percorrido em uma grade, como as ruas de Manhattan.  

---

## ğŸ”¹ **DefiniÃ§Ã£o MatemÃ¡tica da DistÃ¢ncia de Manhattan**  
Dada duas coordenadas \( P = (x_1, y_1) \) e \( Q = (x_2, y_2) \), a distÃ¢ncia de Manhattan Ã© definida como:

\[
D_{Manhattan}(P, Q) = |x_2 - x_1| + |y_2 - y_1|
\]

Em um espaÃ§o multidimensional, a fÃ³rmula se generaliza para \( n \) dimensÃµes:

\[
D_{Manhattan}(P, Q) = \sum_{i=1}^{n} |x_i - y_i|
\]

---

## ğŸ”¹ **Exemplo Manual**  

Se tivermos os pontos \( P(2, 3) \) e \( Q(5, 7) \), entÃ£o:

\[
D_{Manhattan}(P, Q) = |5 - 2| + |7 - 3| = 3 + 4 = 7
\]

---

## ğŸ”¹ **ImplementaÃ§Ã£o em Python**  

Podemos calcular a distÃ¢ncia de Manhattan usando **NumPy** e **scipy.spatial.distance**.

### âœ… **CÃ¡lculo Simples**
```python
import numpy as np

def manhattan_distance(p, q):
    return np.sum(np.abs(np.array(p) - np.array(q)))

# Exemplo
p = (2, 3)
q = (5, 7)
print("DistÃ¢ncia de Manhattan:", manhattan_distance(p, q))  # SaÃ­da: 7
```

### âœ… **Usando `scipy`**
```python
from scipy.spatial.distance import cityblock

# Exemplo com Scipy
print("DistÃ¢ncia de Manhattan (scipy):", cityblock(p, q))  # SaÃ­da: 7
```
ğŸš€ **Nota:** `cityblock(p, q)` implementa diretamente a distÃ¢ncia de Manhattan.

---

## ğŸ”¹ **AplicaÃ§Ã£o no KNN com Scikit-Learn**  
Podemos usar a distÃ¢ncia de Manhattan no **K-Nearest Neighbors (KNN)** definindo o parÃ¢metro `metric='manhattan'`.

### âœ… **KNN usando a DistÃ¢ncia de Manhattan**
```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Carregar dataset
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

# Criar o modelo KNN com distÃ¢ncia de Manhattan
knn = KNeighborsClassifier(n_neighbors=3, metric='manhattan')
knn.fit(X_train, y_train)

# Fazer previsÃµes
y_pred = knn.predict(X_test)

# Avaliar a precisÃ£o
print(f"AcurÃ¡cia: {accuracy_score(y_test, y_pred):.2f}")
```
---

## ğŸ”¹ **ComparaÃ§Ã£o: Manhattan vs Euclidiana**
| DistÃ¢ncia         | FÃ³rmula                                              | Quando usar?                              |
|------------------|-----------------------------------------------------|------------------------------------------|
| **Euclidiana**   | \( \sqrt{\sum (x_i - y_i)^2} \)                     | Quando a diferenÃ§a entre coordenadas Ã© importante. |
| **Manhattan**    | \( \sum |x_i - y_i| \)                              | Quando o deslocamento ocorre em grade (ex: ruas de cidade). |

ğŸ”¹ **Manhattan Ã© menos sensÃ­vel a outliers** porque nÃ£o eleva as diferenÃ§as ao quadrado.  

---

## ğŸ”¹ **ConclusÃ£o**
A distÃ¢ncia de Manhattan mede o deslocamento absoluto entre pontos e Ã© Ãºtil quando os movimentos sÃ£o restritos a direÃ§Ãµes ortogonais (como ruas). No **KNN**, ela pode melhorar a classificaÃ§Ã£o quando as dimensÃµes sÃ£o independentes. ğŸš€