### ğŸ“Œ **DistÃ¢ncia Euclidiana: Entendimento MatemÃ¡tico e AplicaÃ§Ã£o no KNN em Python**  

A **distÃ¢ncia Euclidiana** Ã© a mais comum para medir a proximidade entre dois pontos em um espaÃ§o multidimensional. Ela Ã© baseada no **Teorema de PitÃ¡goras**, calculando a linha reta entre dois pontos.  

---

## ğŸ”¹ **DefiniÃ§Ã£o MatemÃ¡tica da DistÃ¢ncia Euclidiana**  
Dada duas coordenadas \( P = (x_1, y_1) \) e \( Q = (x_2, y_2) \), a distÃ¢ncia Euclidiana Ã© definida como:

\[
D_{Euclidiana}(P, Q) = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}
\]

Em um espaÃ§o multidimensional (\( n \) dimensÃµes), a fÃ³rmula se generaliza para:

\[
D_{Euclidiana}(P, Q) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
\]

---

## ğŸ”¹ **Exemplo Manual**  

Se tivermos os pontos \( P(2, 3) \) e \( Q(5, 7) \), entÃ£o:

\[
D_{Euclidiana}(P, Q) = \sqrt{(5 - 2)^2 + (7 - 3)^2} = \sqrt{3^2 + 4^2} = \sqrt{9 + 16} = \sqrt{25} = 5
\]

---

## ğŸ”¹ **ImplementaÃ§Ã£o em Python**  

Podemos calcular a distÃ¢ncia Euclidiana usando **NumPy** e **scipy.spatial.distance**.

### âœ… **CÃ¡lculo Simples**
```python
import numpy as np

def euclidean_distance(p, q):
    return np.sqrt(np.sum((np.array(p) - np.array(q))**2))

# Exemplo
p = (2, 3)
q = (5, 7)
print("DistÃ¢ncia Euclidiana:", euclidean_distance(p, q))  # SaÃ­da: 5.0
```

### âœ… **Usando `scipy`**
```python
from scipy.spatial.distance import euclidean

# Exemplo com Scipy
print("DistÃ¢ncia Euclidiana (scipy):", euclidean(p, q))  # SaÃ­da: 5.0
```
ğŸš€ **Nota:** `euclidean(p, q)` implementa diretamente a distÃ¢ncia Euclidiana.

---

## ğŸ”¹ **AplicaÃ§Ã£o no KNN com Scikit-Learn**  
A distÃ¢ncia Euclidiana Ã© a **mÃ©trica padrÃ£o** no **K-Nearest Neighbors (KNN)**.

### âœ… **KNN usando a DistÃ¢ncia Euclidiana**
```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Carregar dataset
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

# Criar o modelo KNN com distÃ¢ncia Euclidiana (padrÃ£o)
knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
knn.fit(X_train, y_train)

# Fazer previsÃµes
y_pred = knn.predict(X_test)

# Avaliar a precisÃ£o
print(f"AcurÃ¡cia: {accuracy_score(y_test, y_pred):.2f}")
```
---

## ğŸ”¹ **ComparaÃ§Ã£o: Euclidiana vs Manhattan**
| DistÃ¢ncia         | FÃ³rmula                                              | Quando usar?                              |
|------------------|-----------------------------------------------------|------------------------------------------|
| **Euclidiana**   | \( \sqrt{\sum (x_i - y_i)^2} \)                     | Quando as diferenÃ§as sÃ£o relevantes e queremos medir a linha reta entre pontos. |
| **Manhattan**    | \( \sum |x_i - y_i| \)                              | Quando o deslocamento ocorre em eixos ortogonais (como ruas de cidade). |

ğŸ”¹ **A Euclidiana Ã© mais sensÃ­vel a outliers** porque eleva as diferenÃ§as ao quadrado.

---

## ğŸ”¹ **ConclusÃ£o**
A distÃ¢ncia Euclidiana mede a menor linha reta entre dois pontos e Ã© amplamente usada em aprendizado de mÃ¡quina, incluindo o **KNN**. Em **dados normalizados**, geralmente oferece melhores resultados do que a Manhattan. ğŸš€